"""
Schwab Stock Data Fetcher Module
Handles fetching stock data from Schwab API
"""

import os
import time
import pandas as pd
import requests
from datetime import datetime, timedelta
from typing import List
from schwab_auth import SchwabAuth


class MarketDataFetcher:
    def __init__(self):
        """
        Initialize the MarketDataFetcher class
        """
        self.schwab_auth = SchwabAuth()
        # Create data directory if it doesn't exist
        os.makedirs('data', exist_ok=True)

    def get_symbols_from_file(self, symbols_filepath: str) -> List[str]:
        """Get symbols from file separated by commas"""
        with open(symbols_filepath, 'r') as file:
            symbols = file.read().split(',')
            return [symbol.strip() for symbol in symbols if symbol.strip()]

    def _extract_frequency_number(self, interval) -> int:
        """Extract numeric frequency from interval string (e.g., '5m' -> 5) or return int if already int"""
        try:
            # If it's already an integer, return it directly
            if isinstance(interval, int):
                return interval
            # If it's a string, extract the number
            return int(interval.replace('m', '').replace('h', '').replace('d', ''))
        except (ValueError, AttributeError):
            print(f"‚ö†Ô∏è  Invalid interval format: {interval}, defaulting to 1")
            return 1

    def _get_valid_period(self, days_to_end: int) -> int:
        """
        Get the largest valid period that's not greater than days_to_end.
        Valid periods for periodType=day are [1, 2, 3, 4, 5, 10].
        """
        valid_periods = [1, 2, 3, 4, 5, 10]
        return max([p for p in valid_periods if p <= days_to_end])

    def get_price_history_from_schwab(self, symbol: str, start_date: str, end_date: str, interval_to_fetch: int) -> bool:
        """
        Retrieve price history from Schwab API for each interval from start date to end date

        Args:
            symbol: Stock symbol (e.g., 'SPY')
            start_date: Start date in 'YYYY-MM-DD' format
            end_date: End date in 'YYYY-MM-DD' format
            interval_to_fetch: Interval in minutes (e.g., 1, 5, 15)

        Returns:
            bool: True if successful, False if failed
        """
        if not symbol:
            print("‚ùå Invalid symbol provided")
            return False

        symbol = symbol.upper()

        # Validate credentials first
        if not self.schwab_auth.validate_credentials():
            print("‚ùå Schwab credentials validation failed")
            return False

        # Check if we're authenticated
        if not self.schwab_auth.is_authenticated():
            print("‚ùå Not authenticated with Schwab API")
            return False

        headers = self.schwab_auth.get_auth_headers()
        if not headers:
            print("‚ùå No valid authentication headers available")
            return False

        # Display token info for debugging
        token_info = self.schwab_auth.get_token_info()
        if token_info['valid']:
            remaining_minutes = token_info['seconds_remaining'] / 60
            print(f"üîê Authentication valid - token expires in {remaining_minutes:.1f} minutes")
        else:
            print("‚ùå Token validation failed")
            return False

        url = "https://api.schwabapi.com/marketdata/v1/pricehistory"

        try:
            # Convert string dates to datetime objects
            start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')
        except ValueError as e:
            print(f"‚ùå Invalid date format: {e}")
            return False

        all_candles = []
        current_start_dt = start_date_dt

        while current_start_dt <= end_date_dt:
            # Calculate period based on date range
            days_to_end = (end_date_dt - current_start_dt).days + 1
            
            # Get the largest valid period that fits within our date range
            period = self._get_valid_period(days_to_end)
            
            # Calculate the actual end date based on the period
            current_end_dt = min(current_start_dt + timedelta(days=period-1), end_date_dt)

            # Convert start and end dates to UNIX epoch milliseconds
            start_time_ms = int(current_start_dt.timestamp() * 1000)
            end_time_ms = int(current_end_dt.timestamp() * 1000)

            params = {
                'symbol': symbol,
                'periodType': 'day',
                'period': period,
                'frequencyType': 'minute',
                'frequency': self._extract_frequency_number(interval_to_fetch),  # Use numeric frequency
                'startDate': start_time_ms,
                'endDate': end_time_ms,
                'needExtendedHoursData': 'false',
                'needPreviousClose': 'false'
            }

            print(f"üì° Fetching price history for {symbol} ({interval_to_fetch}) from {current_start_dt.date()} to {current_end_dt.date()}")
            print(f"üîç API URL: {url}")
            print(f"üîç API Params: {params}")

            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                # Sleep for 1 second to avoid rate limiting
                time.sleep(1)

                if response.status_code == 200:
                    data = response.json()

                    if 'candles' in data and data['candles']:
                        candles = data['candles']
                        print(f"‚úÖ Retrieved {len(candles)} candles from Schwab API")
                        all_candles.extend(candles)
                    else:
                        print("üìä No candle data found in API response")
                else:
                    print(f"‚ùå API request failed: {response.status_code}")
                    if response.text:
                        print(f"Response: {response.text[:200]}...")
                    return False

            except requests.exceptions.RequestException as e:
                print(f"‚ùå Network error fetching price history: {e}")
                return False
            except Exception as e:
                print(f"‚ùå Unexpected error fetching price history: {e}")
                return False

            # Move to next time window
            current_start_dt = current_end_dt + timedelta(days=1)  # Add 1 day to avoid overlap

            # Process and save the data if we have candles
            if all_candles:
                try:
                    # Convert candles to DataFrame with proper structure
                    df_data = []
                    for candle in all_candles:
                        df_data.append({
                            'timestamp': candle.get('datetime', 0),
                            'datetime': datetime.fromtimestamp(candle.get('datetime', 0) / 1000).strftime('%Y-%m-%d %H:%M:%S'),
                            'open': candle.get('open', 0),
                            'high': candle.get('high', 0),
                            'low': candle.get('low', 0),
                            'close': candle.get('close', 0),
                            'volume': candle.get('volume', 0)
                        })

                    new_df = pd.DataFrame(df_data)

                    # Sort by timestamp and remove duplicates
                    new_df = new_df.sort_values('timestamp').drop_duplicates(subset=['timestamp'])

                    # Check if existing file exists
                    csv_filename = f"data/{symbol}_{interval_to_fetch}.csv"
                    if os.path.exists(csv_filename):
                        print(f"üìÇ Found existing data file for {symbol}_{interval_to_fetch}")
                        # Read existing data
                        existing_df = pd.read_csv(csv_filename)
                        # Convert timestamp to numeric for proper comparison
                        existing_df['timestamp'] = pd.to_numeric(existing_df['timestamp'])

                        # Combine existing and new data
                        combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                        # Sort by timestamp and remove duplicates
                        combined_df = combined_df.sort_values('timestamp').drop_duplicates(subset=['timestamp'])

                        print(f"üìä Combined data: {len(existing_df)} existing + {len(new_df)} new = {len(combined_df)} total records")
                        # Save combined data
                        combined_df.to_csv(csv_filename, index=False)
                        print(f"üíæ Updated {csv_filename} with combined data")
                    else:
                        # Save new data
                        new_df.to_csv(csv_filename, index=False)
                        print(f"üíæ Created new file {csv_filename} with {len(new_df)} records")

                except Exception as e:
                    print(f"‚ùå Error processing data: {e}")
                    return False
            else:
                print(f"‚ö†Ô∏è  No data retrieved for {symbol}_{interval_to_fetch}")

        return True

    def aggregate_data(self):
        """
        Aggregate data from all symbols and intervals
        """
        for symbol in self.symbols:
            success = self.get_price_history_from_schwab(symbol)
            if success and self.intervals_to_aggregate_to:  # Only aggregate if intervals_to_aggregate_to is not None
                self.aggregate_data_for_symbol(symbol)
            elif not success:
                print(f"‚ö†Ô∏è Skipping aggregation for {symbol} due to failed data fetch")

        print("üéâ All data fetched successfully")

    def aggregate_data_for_symbol(self, symbol: str):
        """
        Aggregate data for a single symbol

        Args:
            symbol: Stock symbol (e.g., 'SPY')
        """
        if not self.intervals_to_aggregate_to:  # Early return if no intervals to aggregate to
            return

        for interval in self.intervals_to_aggregate_to:
            start_interval_frequency = self._extract_frequency_number(interval)
            # If start interval < interval and interval % start_interval == 0 and interval is not in the data directory, then aggregate
            if start_interval_frequency < self._extract_frequency_number(interval) and self._extract_frequency_number(interval) % start_interval_frequency == 0 and not os.path.exists(f"{self.data_dir}/{symbol}_{interval}.csv"):
                print(f"üîÑ Aggregating {symbol}_{interval}")

                # Aggregate the data to the interval to aggregate to
                df = pd.read_csv(f"{self.data_dir}/{symbol}_{interval}.csv")
                df = df.resample(interval).agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last',
                    'volume': 'sum'
                }).dropna()

                # Save the aggregated data
                df.to_csv(f"data/{symbol}_{interval}.csv", index=False)
                print(f"üíæ Created new file {symbol}_{interval}.csv with {len(df)} records")

if __name__ == "__main__":
    for interval in ["30m"]:
        market_data_fetcher = MarketDataFetcher()
        market_data_fetcher.get_price_history_from_schwab("SPY", "2025-01-01", "2025-06-17", interval)
